{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1649a5-2d60-4b2d-aa7d-5da97bab16e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24499381-5417-4b49-8232-389f4c6659a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = 'Your API key'\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae8380-2e8e-4d2f-a1a1-f0cd8e684682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_response = openai.File.create(\n",
    "  file=open('1000.jsonl', \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "upload_response\n",
    "file_id = upload_response.id\n",
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372750b-8a2f-4cc1-80fe-c246323fecd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_response = openai.File.create(\n",
    "  file=open('pre_done/Validation_n.jsonl', \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "upload_response\n",
    "file_id2 = upload_response.id\n",
    "file_id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615daeb7-feb4-4ceb-be14-b406f1fa346f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32e872-4432-4a6d-a957-11179753129c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start training and wait. Be aware of costs before starting.\n",
    "response = openai.FineTuningJob.create(training_file=file_id, model=\"babbage-002\",\n",
    "                                       hyperparameters={'n_epochs':6})\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f413ab1-ab7a-490a-baab-e1e080c571ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Can be used to monitor the status\n",
    "status = openai.FineTuningJob.list_events(id=job_id, limit=5)\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbc7c1-9867-4715-bbd8-b9f851a9ba8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cae64f-1a44-4678-ae79-5eca65184e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Try out a single response\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"the number of your trained model\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Write a very concise procedure given the reactants and products, esterification reaction. Use one word actions and precise temperatures and durations. Skip measurements.\"},\n",
    "    {\"role\": \"user\", \"content\": \"CCO.O=C(O)c1ccccc1-c1ccc(C(F)(F)F)cc1>>O=C([O-])c1ccccc1-c1ccc(C(F)(F)F)cc1 ->\"}\n",
    "  ],\n",
    "  stop=[\" \\n\"],\n",
    "  max_tokens=100,\n",
    "  temperature=0.05)\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6808a6-e7e2-4214-ad66-bf2673eecb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple queries for the entire Validation or Testing dataset. Be aware of the costs.\n",
    "#Can take a while if the servers are experiencing a heavy load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3e28fb-2744-4559-bc0e-6978be21327d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3bf73-a408-48c9-a981-0a23d77972fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For 3.5-turbo\n",
    "with open('pre_done/Testing.jsonl', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "predictions = []\n",
    "for line in tqdm(lines):\n",
    "    time.sleep(3)\n",
    "    entry = json.loads(line)\n",
    "    \n",
    "    new_prompt = entry['prompt']\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "  model=\"the number of your trained model\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Write a very concise procedure given the reactants and products, esterification reaction. Use one word actions and precise temperatures and durations. Skip measurements.\"},\n",
    "    {\"role\": \"user\", \"content\": new_prompt}\n",
    "  ],\n",
    "  stop=[\" \\n\"],\n",
    "  max_tokens=100,\n",
    "  temperature=0.05)\n",
    "    \n",
    "    prediction = completion.choices[0].message['content'][1:]\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Step 3: Write the predictions to a new text file\n",
    "with open('file_name_to_save.txt', 'w') as file:\n",
    "    for prediction in predictions:\n",
    "        file.write(f\"{prediction}\\n\".replace('\\u00b0',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e553fe5-846a-4c3c-b5a2-c39179788bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9debbef-8a4c-4c01-b3dc-469249545399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62cd28e-4dcc-470d-a079-e8857c2627bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For davinci and babbage\n",
    "from tqdm import tqdm\n",
    "with open('pre_done/Testing.jsonl', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Step 2: Loop through each entry, extract the prompt, and get a prediction\n",
    "predictions = []\n",
    "for line in tqdm(lines):\n",
    "    time.sleep(2)\n",
    "    entry = json.loads(line)\n",
    "    #print(entry)\n",
    "    \n",
    "    new_prompt = entry['prompt']\n",
    "   \n",
    "    answer = openai.Completion.create(\n",
    "        model='the number of your trained model',\n",
    "        prompt=new_prompt,\n",
    "        max_tokens=120,\n",
    "        stop=[\" \\n\"],\n",
    "         temperature=0.05\n",
    "    )\n",
    "\n",
    "    \n",
    "    prediction = answer['choices'][0]['text'][1:]\n",
    "    predictions.append(prediction)\n",
    "\n",
    "\n",
    "with open('file_name_to_save.txt', 'w') as file:\n",
    "    for prediction in predictions:\n",
    "        file.write(f\"{prediction}\\n\".replace('\\u00b0',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42cd20c-fd70-4048-a962-92737731d43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate BLEU from a file\n",
    "\n",
    "import json\n",
    "import sacrebleu\n",
    "\n",
    "prediction_file_name = 'path to your file with predictions'\n",
    "\n",
    "with open('pre_done/Testing.jsonl', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    correct_answers = [json.loads(line)['completion'] for line in lines]\n",
    "\n",
    "with open(prediction_file_name, 'r') as file:\n",
    "    predictions = [line.strip() for line in file.readlines()]\n",
    "\n",
    "correct_answers_str = [' '.join(ans.split()) for ans in correct_answers]\n",
    "predictions_str = [' '.join(pred.split()) for pred in predictions]\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(predictions_str, [correct_answers_str])\n",
    "print(f'BLEU score: {bleu.score:.4f}')\n",
    "print(f'Individual n-gram precisions: {bleu.precisions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdaddf-3f10-4312-9e07-00cf65d56bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
